\section{The LZ77 Algorithm} \label{sec:lz77}
In this section we provide a short overview of the dictionary-based compression algorithm presented by Abrham Lempel and Jacob Ziv in 1977 \cite{ziv1}. The aim of this algorithm is trying to reduce the redundancy due to similar sequence repeating along the message. What it does is basically checking if a certain piece of the sequence has already been found in the past and, if it is the case, we code the whole piece with a reference to the previous alike sequence.

\subsection{The algorithm} \label{subsec:lz77alg}
The algorithm works with two adjacent windows shifting on the right during the coding of the message. The first window is the \textit{searching window} and has length $L_s$; the second one is the \textit{coding window} and has length $L_c$. We want to find a match between any prefix of the \textit{coding window} and a sequence contained in the overall window given by the juxtapposition of the \textit{searching window} and the \textit{coding window}, i.e. it is sufficient that only the first symbol of the match belongs to the \textit{searching window}, while the matched pattern can stretch in through the \textit{coding window} itself. The window lengths $L_s$ and $L_c$ are two parameters of the algorithm and their choice strongly influences the compression performances, we will see how in the last part of this report.
 
Once we have found a match between a prefix of the \textit{coding window} and another piece of message, we code it as a triplet (\textit{offset}, \textit{length}, \textit{symbol}) where:
\begin{itemize}
\item
\textbf{offset} denotes the number of back hops we have to do, starting from the first symbol of the \textit{coding sequence}, to find the beginning of the matched string; it is clear that, for how it is defined, the \textit{offset} cannot exceeds the \textit{searching window} dimension;

\item
\textbf{length} is the length of the matched string or, equivalently, of the prefix of the \textit{coding window} which has been matched. This value cannot exceed $L_c$, since this is the maximum dimension of the pattern we are looking for;

\item
\textbf{symbol} is the first symbol after the matched prefix of the \textit{coding window}. Its encoding assures the functioning of the algorithm also in case of no matches. 
\end{itemize}

After the generation and the storage of a triplet inside the dictionary, we shift the windows such that the first symbol of the \textit{coding window} corresponds to the first non encoded symbol.

\subsection{LZ77 Implementation} \label{subsec:lz77implem}
In the following paragraphs we will present our own implementation in Matlab of the algorithm, spanning the different versions we produced. As a matter of fact, several editions of the same program have been written, adopting different approaches in some parts of the code. Actually the versions differ above all for the pattern matching that has been adopted, while the rest of the code remains basically the same.

\subsubsection{Basic Coding Algorithm} \label{subsubsec:basiclz77}
First of all we choose a file and write it as a sequence of bytes (\texttt{uint8} in Matlab). We assume this is the original message, whose alphabet is made of all the possible combinations of $8$ bit and has size $M = 2^8 = 256$. The first symbol of the sequence is encoded as a single symbol directly, because placing the \textit{coding window} in the first positions makes no sense, since we would have no \textit{searching window} to exploit. Then, the \textit{coding window} starts from the second position of the sequence and, until there are at least $L_s$ symbols before it, the \textit{searching window} is shrunk to fit the available positions. The same thing happen to the \textit{coding window} when we are reaching the end of the file: if less than $L_c$ symbols are left, we use a shorter \textit{coding window}. Note that, in order to have always a symbol to insert in the \textit{symbol} field of the last triplet, near the end of the file the \textit{coding window} is shrunk such that the last symbol of the stream is left out.

Once the dictionary has been created, we want to write it using the least amount of memory we can. Since the values of $L_s$ and $L_c$ are fixed and determine the maximum values for the fields \textit{offset} and \textit{length} and we know that a symbol is represented with a single byte, we can estimate a maximum number of bytes to use for each triplet as:
\begin{align}
l_{offset} &= \left \lceil \frac{\lceil log_2L_s \rceil}{8} \right \rceil \text{bytes} \\
l_{length} &= \left \lceil \frac{\lceil log_2(L_s + L_c - 1) \rceil }{8} \right \rceil \text{bytes} 
\end{align}

We use exactly $l_{offset} + l_{length} + 1$ bytes for each triplet and encode separately its three components. Then we create the message to be sent by concatenating the bytes related to each entry of the dictionary, starting from the first one. Since we use a constant number of bytes for each entry and the receiver knows how many bytes are employed for each triplet component, it is easy to build the dictionary at the receiver side and perform the decoding to restore the original file.

\subsubsection{Version 1: Basic}
As previously mentioned, the several versions of the algorithms differs by their pattern matching technique to find The first, basic, version of the program executes the pattern matching by brute force: we compare the first character of the \textit{coding window} with each element of the \textit{search window}. When a match occurs, we compare the second element of the \textit{coding window} with the following symbol of the \textit{search window} and so on until we find two different symbols. Then, if the length of the match is longer than the longest match found so far, we replace it and save also the starting point of the match in the \textit{search window}. If, in the end, the longest match has zero length, this means that no match has been found and we have to encode one only symbol. This basic algorithm is very wasteful, because we have to try every possible position.

\subsubsection{Version 2: KMP}
A first improvement has been brought by using the KMP (Knuth-Morris-Pratt) pattern mathcing algorithm \cite{knuth1}. This algorithm is optimum for the research of a pattern inside a string: it takes a time $\mathcal{O}(n + k)$, where $n$ is the length of the pattern and $k$ is the length of the string. We though about using the KMP algorithm where the pattern $\mathbf{c}$ is the \textit{coding window} and the overall string $[\mathbf{s}, \mathbf{c}]$ is the \textit{search window} concatenated with the \textit{coding window}.

The KMP algorithm starts with the brute force approach, comparing the first character of the pattern with each character of the string, but it allows to improve performances in pattern matching because, thanks to previous failed matches, it realize when it is possible to jump ahead and discard some trials, which will surely fail. We used the "jump mechanism" of KMP to realize a second version of the program, but the time performances keep remaining very poor, due to the many nested cycle we have to use, which are not very fast to be executed in Matlab. Moreover, each different pattern needs a \textit{matching function} to be computed, which increases the number of necessary computations.

\subsubsection{Version 3: optimistic \texttt{strfind()}}
The third version uses the Matlab function \texttt{strfind()} for pattern matching, which is optimized to work in Matlab. We simply invoke this method using the \textit{search window} as string and the \textit{coding window} as pattern to be found. If no matches occurs we discard the last symbol of the \textit{coding window} and repeat the procedure until either a match is found or we reduce the length of the pattern to zero, that means that we have to encode the symbol individually.

The term \textit{optimistic} refers to the order we take different pattern: we are confident to find the longest match, and then the best one, quite soon and therefore we start by looking for the entire pattern. Of course, if there is little redundancy and there is often no match found, we have to repeat the cycle $L_c$ times for each different \textit{coding window}.

\subsubsection{Version 4: pessimistic \texttt{strfind()}} \label{subsubsec:pess}
From an empirical point of view we found that, often, we have not many long matches and hence the \textit{optimistic} approach is not very suitable. The \textit{pessimistic} approach consists in starting to look for a match with the shortest possible prefix of the \textit{coding window} and executing the pattern matching through \texttt{strfind()} until we find no more matches. In this case we consider the previous match, which is the longest one, to build the current triplet. If there are no matches we know it from the first iteration and this allows us to save a lot of time.

This fourth version results to be the faster one; anyway, we must be aware that performances are stringly influenced by what kind of file we are trying to compress. Our experiments involved most of all text files or human-written files, which do not present a large redundancy. On one hand this makes the \textit{pessimistic} approach the best one in terms of time performances; on the other hand, the LZ77 algorithm is not the best choice for compression for files with low autocorrelation.

All the results presented in the following has been obtained with this version of the program.